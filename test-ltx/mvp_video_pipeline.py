"""
KRACKER MVP - AI Video Pipeline with Google ADK
================================================
Multi-Agent system using Google Agent Development Kit

Usage:
    python mvp_video_pipeline.py "AIê°€ ë°”ê¾¸ëŠ” ë¯¸ë˜ ì§ì—…" 1

Requirements:
    pip install google-adk google-genai moviepy gtts python-dotenv pillow
"""

import os
import sys
import json
import asyncio
from pathlib import Path
from typing import Optional, Any

# ===== í™˜ê²½ ì„¤ì • =====
from dotenv import load_dotenv
from datetime import datetime
import re
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
OUTPUT_BASE_DIR = Path(__file__).parent / "output"
OUTPUT_BASE_DIR.mkdir(exist_ok=True)

# í˜„ì¬ í”„ë¡œì íŠ¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ (run_pipelineì—ì„œ ì„¤ì •ë¨)
OUTPUT_DIR = OUTPUT_BASE_DIR  # ê¸°ë³¸ê°’


def create_project_folder(title: str) -> Path:
    """
    í”„ë¡œì íŠ¸ë³„ êµ¬ì¡°í™”ëœ í´ë” ìƒì„±

    Args:
        title: ì˜ìƒ ì œëª©

    Returns:
        í”„ë¡œì íŠ¸ í´ë” ê²½ë¡œ

    Structure:
        output/
        â””â”€â”€ 2026-02-03_AIê°€-ë°”ê¾¸ëŠ”-ë¯¸ë˜-ì§ì—…/
            â”œâ”€â”€ images/      # ì”¬ë³„ ì´ë¯¸ì§€
            â”œâ”€â”€ audio/       # ë‚˜ë ˆì´ì…˜ ìŒì„±
            â”œâ”€â”€ video/       # ìµœì¢… ì˜ìƒ
            â””â”€â”€ metadata/    # JSON ë©”íƒ€ë°ì´í„°
    """
    # ì œëª©ì—ì„œ í´ë”ëª… ìƒì„± (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
    safe_title = re.sub(r'[<>:"/\\|?*]', '', title)
    safe_title = safe_title.replace(' ', '-')[:50]  # ê³µë°±ì„ í•˜ì´í”ˆìœ¼ë¡œ, ìµœëŒ€ 50ì

    # íƒ€ì„ìŠ¤íƒ¬í”„ + ì œëª©ìœ¼ë¡œ í´ë”ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y-%m-%d_%H%M%S")
    folder_name = f"{timestamp}_{safe_title}"

    project_dir = OUTPUT_BASE_DIR / folder_name

    # í•˜ìœ„ í´ë” ìƒì„±
    (project_dir / "images").mkdir(parents=True, exist_ok=True)
    (project_dir / "audio").mkdir(parents=True, exist_ok=True)
    (project_dir / "video").mkdir(parents=True, exist_ok=True)
    (project_dir / "metadata").mkdir(parents=True, exist_ok=True)

    # ì´ˆê¸° metadata ìƒì„±
    _init_metadata(project_dir, title)

    print(f"ğŸ“ í”„ë¡œì íŠ¸ í´ë” ìƒì„±: {project_dir}")

    return project_dir


def _init_metadata(project_dir: Path, title: str):
    """íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹œ ì´ˆê¸° metadata ìƒì„±"""
    metadata_dir = project_dir / "metadata"

    pipeline_output = {
        "generated_at": datetime.now().isoformat(),
        "project_folder": str(project_dir),
        "title": title,
        "status": "in_progress",
        "scene_count": 0,
        "files": {
            "script": "",
            "narration": "",
            "images": "",
            "audio": "",
            "video": ""
        },
        "script": {"title": title, "scenes": []},
        "audio": {"audio_path": "", "timestamps": [], "duration": 0},
        "images": {"count": 0, "image_paths": [], "scenes": []}
    }

    pipeline_path = metadata_dir / "pipeline_output.json"
    with open(pipeline_path, "w", encoding="utf-8") as f:
        json.dump(pipeline_output, f, ensure_ascii=False, indent=2)

# ===== Google ADK Imports =====
from google.adk.agents import LlmAgent, SequentialAgent, ParallelAgent
from google.adk.tools import FunctionTool, ToolContext
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types

# ===== Gemini Client =====
from google import genai
gemini_client = genai.Client(api_key=GEMINI_API_KEY)

# ===== Global State (ADK tool_context.state ë™ê¸°í™” ë¬¸ì œ í•´ê²°ìš©) =====
# ADKì˜ tool_context.stateê°€ session.stateë¡œ ì œëŒ€ë¡œ ì „ë‹¬ë˜ì§€ ì•ŠëŠ” ì´ìŠˆ í•´ê²°
GLOBAL_STATE = {
    "script": None,
    "images": None,
    "audio": None,
    "video": None,
}


# ============================================================
# TOOLS - Custom Tools for Agents
# ============================================================

def save_script_tool(script_json: dict, tool_context: ToolContext) -> dict:
    """
    ìŠ¤í¬ë¦½íŠ¸ ì €ì¥ ë„êµ¬ - ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ stateì™€ metadataì— ì €ì¥
    Args:
        script_json: ìŠ¤í¬ë¦½íŠ¸ JSON (title, scenes í¬í•¨)
    Returns:
        ì €ì¥ ê²°ê³¼
    """
    # metadataì— ì €ì¥
    metadata_dir = OUTPUT_DIR / "metadata" if (OUTPUT_DIR / "metadata").exists() else OUTPUT_DIR
    script_path = metadata_dir / "script.json"

    with open(script_path, "w", encoding="utf-8") as f:
        json.dump(script_json, f, ensure_ascii=False, indent=2)

    # pipeline_output.json ì—…ë°ì´íŠ¸
    pipeline_path = metadata_dir / "pipeline_output.json"
    if pipeline_path.exists():
        with open(pipeline_path, "r", encoding="utf-8") as f:
            pipeline_data = json.load(f)
        pipeline_data["script"] = script_json
        pipeline_data["scene_count"] = len(script_json.get("scenes", []))
        with open(pipeline_path, "w", encoding="utf-8") as f:
            json.dump(pipeline_data, f, ensure_ascii=False, indent=2)

    print(f"  ğŸ“ ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}")
    print(f"  âœ“ ì œëª©: {script_json.get('title', 'Unknown')}")
    print(f"  âœ“ ì”¬ ê°œìˆ˜: {len(script_json.get('scenes', []))}")

    result = {"script": script_json, "path": str(script_path)}
    tool_context.state["script"] = script_json  # ADK Stateì— ì €ì¥
    GLOBAL_STATE["script"] = script_json  # Global Stateì—ë„ ì €ì¥
    return result


def generate_images_tool(visual_descriptions: list[str], tool_context: ToolContext) -> dict:
    """
    ì´ë¯¸ì§€ ìƒì„± ë„êµ¬
    Args:
        visual_descriptions: ì”¬ë³„ ì´ë¯¸ì§€ ì„¤ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ì–´)
    Returns:
        ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    image_paths = []
    images_dir = OUTPUT_DIR / "images" if (OUTPUT_DIR / "images").exists() else OUTPUT_DIR

    for i, prompt in enumerate(visual_descriptions):
        scene_id = i + 1
        image_path = images_dir / f"scene_{scene_id}.png"

        print(f"  ğŸ¨ ì”¬ {scene_id} ì´ë¯¸ì§€ ìƒì„± ì¤‘...")

        try:
            # Nano Banana Pro (Gemini 3 Pro Image) ì‚¬ìš©
            try:
                response = gemini_client.models.generate_content(
                    model="gemini-3-pro-image-preview",
                    contents=f"Generate an ultra high quality image: {prompt}. Style: 4K resolution, ultra-detailed, cinematic lighting, professional photography, sharp focus, vibrant colors, masterpiece quality, photorealistic rendering.",
                    config=types.GenerateContentConfig(
                        response_modalities=["IMAGE", "TEXT"]
                    )
                )

                # ì´ë¯¸ì§€ íŒŒíŠ¸ ì°¾ê¸°
                if response.candidates and response.candidates[0].content.parts:
                    for part in response.candidates[0].content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            with open(image_path, "wb") as f:
                                f.write(part.inline_data.data)
                            image_paths.append(str(image_path))
                            print(f"    âœ“ Nano Banana Pro ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ ğŸŒ")
                            break
                    else:
                        raise Exception("ì´ë¯¸ì§€ íŒŒíŠ¸ ì—†ìŒ")
                else:
                    raise Exception("ì‘ë‹µ ì—†ìŒ")

            except Exception as gemini_err:
                print(f"    âš  Gemini ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {gemini_err}")
                raise gemini_err

        except Exception as e:
            print(f"    â†’ Placeholder ì´ë¯¸ì§€ ìƒì„±")
            # Placeholder ìƒì„±
            _create_placeholder_image(image_path, scene_id, prompt)
            image_paths.append(str(image_path))

    result = {"image_paths": image_paths, "count": len(image_paths)}
    tool_context.state["images"] = result  # ADK Stateì— ì €ì¥
    GLOBAL_STATE["images"] = result  # Global Stateì—ë„ ì €ì¥
    return result


def generate_audio_tool(narration_texts: list[str], tool_context: ToolContext) -> dict:
    """
    ìŒì„± ìƒì„± ë„êµ¬
    Args:
        narration_texts: ì”¬ë³„ ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    Returns:
        ìŒì„± íŒŒì¼ ê²½ë¡œì™€ íƒ€ì„ìŠ¤íƒ¬í”„
    """
    full_text = " ".join(narration_texts)
    audio_dir = OUTPUT_DIR / "audio" if (OUTPUT_DIR / "audio").exists() else OUTPUT_DIR
    audio_path = audio_dir / "narration.mp3"

    print("  ğŸ™ï¸ ìŒì„± ìƒì„± ì¤‘...")

    # Qwen3-TTS ì‹œë„ (2026ë…„ 1ì›” ê³µì‹ ë¦´ë¦¬ì¦ˆ)
    try:
        import torch
        import soundfile as sf
        from qwen_tts import Qwen3TTSModel
        print("    Qwen3-TTS ì‚¬ìš© (qwen-tts íŒ¨í‚¤ì§€)")

        # Qwen3-TTS ëª¨ë¸ ë¡œë“œ (0.6B ê²½ëŸ‰ ë²„ì „)
        # CPU ëª¨ë“œ - AMD gfx1151 MIOpen í˜¸í™˜ì„± ë¬¸ì œë¡œ GPU ì‚¬ìš© ì‹œ ìŒì„± ê¹¨ì§
        device = "cpu"
        dtype = torch.float32
        print(f"    TTS ë””ë°”ì´ìŠ¤: {device} (CPU ëª¨ë“œ)")

        model = Qwen3TTSModel.from_pretrained(
            "Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice",
            device_map=device,
            dtype=dtype,
        )

        wav_path = audio_dir / "narration.wav"

        # ìŒì„± ìƒì„± (í•œêµ­ì–´ í™”ì: Sohee)
        wavs, sample_rate = model.generate_custom_voice(
            text=full_text,
            language="Korean",
            speaker="Sohee",  # í•œêµ­ì–´ ì—¬ì„± í™”ì
        )

        # WAV íŒŒì¼ ì €ì¥
        sf.write(str(wav_path), wavs[0], sample_rate)
        print(f"    âœ“ Qwen3-TTS ìŒì„± ìƒì„± ì™„ë£Œ: {wav_path}")

        # MP3 ë³€í™˜
        try:
            from moviepy import AudioFileClip
            import moviepy
            moviepy_v2 = int(moviepy.__version__.split('.')[0]) >= 2
        except ImportError:
            from moviepy.editor import AudioFileClip
            moviepy_v2 = False

        audio = AudioFileClip(str(wav_path))
        if moviepy_v2:
            audio.write_audiofile(str(audio_path))
        else:
            audio.write_audiofile(str(audio_path), verbose=False, logger=None)

        # ì”¬ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì • (ê¸€ì ìˆ˜ ê¸°ë°˜)
        timestamps = []
        current_time = 0
        chars_per_second = 5.0  # Qwen TTSëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì†ë„

        for i, text in enumerate(narration_texts):
            duration = len(text) / chars_per_second
            timestamps.append({
                "scene_id": i + 1,
                "start": current_time,
                "end": current_time + duration
            })
            current_time += duration

        audio.close()

        result = {
            "audio_path": str(audio_path),
            "timestamps": timestamps,
            "duration": current_time
        }
        tool_context.state["audio"] = result  # ADK Stateì— ì €ì¥
        GLOBAL_STATE["audio"] = result  # Global Stateì—ë„ ì €ì¥
        return result
    except ImportError as e:
        print(f"    âš  Qwen3-TTS ë¯¸ì„¤ì¹˜: {e}")
        # ImportErrorë§Œ fallback í—ˆìš© (íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ ì‹œ)
    except Exception as e:
        # Qwen-TTSê°€ ë¡œë“œëì§€ë§Œ ì‹¤í–‰ ì‹¤íŒ¨ â†’ fallback ì—†ì´ ì—ëŸ¬ ë°œìƒ
        raise RuntimeError(f"Qwen3-TTS ì‹¤í–‰ ì‹¤íŒ¨: {e}") from e

    # gTTS fallback
    try:
        from gtts import gTTS
        print("    gTTS ì‚¬ìš©")
        tts = gTTS(text=full_text, lang='ko')
        tts.save(str(audio_path))

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì •
        timestamps = []
        current_time = 0
        chars_per_second = 4.5

        for i, text in enumerate(narration_texts):
            duration = len(text) / chars_per_second
            timestamps.append({
                "scene_id": i + 1,
                "start": current_time,
                "end": current_time + duration
            })
            current_time += duration

        result = {
            "audio_path": str(audio_path),
            "timestamps": timestamps,
            "duration": current_time
        }
        tool_context.state["audio"] = result  # ADK Stateì— ì €ì¥
        GLOBAL_STATE["audio"] = result  # Global Stateì—ë„ ì €ì¥
        return result
    except ImportError:
        print("    âš  TTS ì—†ìŒ")
        result = {"audio_path": "", "timestamps": [], "duration": 0}
        tool_context.state["audio"] = result  # ADK Stateì— ì €ì¥
        GLOBAL_STATE["audio"] = result  # Global Stateì—ë„ ì €ì¥
        return result


def render_video_tool(
    image_paths: list[str],
    audio_path: str,
    timestamps: list[dict],
    tool_context: ToolContext
) -> dict:
    """
    ì˜ìƒ ë Œë”ë§ ë„êµ¬ (Remotion ì‚¬ìš©)
    Args:
        image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        audio_path: ìŒì„± íŒŒì¼ ê²½ë¡œ
        timestamps: ì”¬ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
    Returns:
        ìµœì¢… ì˜ìƒ ê²½ë¡œ
    """
    import subprocess
    from datetime import datetime

    print("  ğŸ¬ Remotion ë Œë”ë§ ì¤€ë¹„ ì¤‘...")

    # ì´ ì¬ìƒ ì‹œê°„ ê³„ì‚°
    total_duration = timestamps[-1]["end"] if timestamps else 30

    # 1. pipeline_output.json ìƒì„±
    metadata_dir = OUTPUT_DIR / "metadata"
    metadata_dir.mkdir(parents=True, exist_ok=True)

    # ì”¬ ì •ë³´ êµ¬ì„±
    scenes = []
    for i, ts in enumerate(timestamps):
        scenes.append({
            "id": i + 1,
            "narration": f"Scene {i + 1}",
            "visual_description": f"Scene {i + 1} visual",
            "duration_seconds": ts["end"] - ts["start"]
        })

    pipeline_output = {
        "generated_at": datetime.now().isoformat(),
        "title": "KRACKER Generated Video",
        "scene_count": len(image_paths),
        "files": {
            "script": "script.json",
            "narration": "narration.json",
            "images": "images.json",
            "audio": "narration.mp3",
            "video": "final_video_remotion.mp4"
        },
        "script": {
            "title": "KRACKER Generated Video",
            "scenes": scenes
        },
        "audio": {
            "audio_path": "output/narration.mp3",
            "timestamps": timestamps,
            "duration": total_duration
        },
        "images": {
            "count": len(image_paths),
            "image_paths": [f"output/scene_{i+1}.png" for i in range(len(image_paths))],
            "scenes": [
                {"scene_id": i + 1, "prompt": f"Scene {i + 1}", "image_path": f"output/scene_{i+1}.png"}
                for i in range(len(image_paths))
            ]
        }
    }

    # JSON ì €ì¥
    pipeline_json_path = metadata_dir / "pipeline_output.json"
    with open(pipeline_json_path, "w", encoding="utf-8") as f:
        json.dump(pipeline_output, f, ensure_ascii=False, indent=2)
    print(f"    âœ“ pipeline_output.json ìƒì„± ì™„ë£Œ")

    # 2. Remotion ë Œë”ë§ í˜¸ì¶œ
    print("  ğŸ¬ Remotion ë Œë”ë§ ì‹œì‘...")

    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ (kracker/)
    project_root = Path(__file__).parent.parent
    render_script = project_root / "scripts" / "render-video.js"

    # OUTPUT_DIRì˜ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
    relative_output_dir = OUTPUT_DIR.relative_to(project_root)

    try:
        result = subprocess.run(
            ["node", str(render_script), str(relative_output_dir)],
            cwd=str(project_root),
            capture_output=True,
            text=True,
            timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
        )

        if result.returncode == 0:
            video_path = OUTPUT_DIR / "video" / "final_video_remotion.mp4"
            print(f"    âœ“ Remotion ë Œë”ë§ ì™„ë£Œ: {video_path}")
            result_dict = {"video_path": str(video_path), "success": True}
        else:
            print(f"    âš  Remotion ë Œë”ë§ ì‹¤íŒ¨: {result.stderr}")
            # Fallback: MoviePy ì‚¬ìš©
            result_dict = _fallback_moviepy_render(image_paths, audio_path, timestamps)
    except subprocess.TimeoutExpired:
        print("    âš  Remotion íƒ€ì„ì•„ì›ƒ, MoviePy fallback ì‚¬ìš©")
        result_dict = _fallback_moviepy_render(image_paths, audio_path, timestamps)
    except FileNotFoundError:
        print("    âš  Node.js ì—†ìŒ, MoviePy fallback ì‚¬ìš©")
        result_dict = _fallback_moviepy_render(image_paths, audio_path, timestamps)

    tool_context.state["video"] = result_dict
    GLOBAL_STATE["video"] = result_dict  # Global Stateì—ë„ ì €ì¥
    return result_dict


def _fallback_moviepy_render(image_paths: list[str], audio_path: str, timestamps: list[dict]) -> dict:
    """MoviePy fallback ë Œë”ë§"""
    import moviepy
    moviepy_version = int(moviepy.__version__.split('.')[0])

    if moviepy_version >= 2:
        from moviepy import ImageClip, AudioFileClip, concatenate_videoclips
        USE_V2 = True
    else:
        from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips
        USE_V2 = False

    print("  ğŸ¥ MoviePy fallback ë Œë”ë§...")

    try:
        audio = AudioFileClip(audio_path)
        total_duration = audio.duration
    except:
        total_duration = timestamps[-1]["end"] if timestamps else 30
        audio = None

    clips = []
    for i, image_path in enumerate(image_paths):
        duration = timestamps[i]["end"] - timestamps[i]["start"] if i < len(timestamps) else 5
        if duration <= 0:
            duration = 5
        try:
            clip = ImageClip(image_path, duration=duration)
            if USE_V2:
                clip = clip.resized(height=1080)
            else:
                clip = clip.resize(height=1080)
            clips.append(clip)
        except Exception as e:
            print(f"    í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")

    if not clips:
        return {"video_path": "", "success": False}

    final_video = concatenate_videoclips(clips, method="compose")
    if audio:
        if USE_V2:
            final_video = final_video.with_audio(audio)
        else:
            final_video = final_video.set_audio(audio)

    video_dir = OUTPUT_DIR / "video"
    video_dir.mkdir(parents=True, exist_ok=True)
    output_path = video_dir / "final_video.mp4"

    if USE_V2:
        final_video.write_videofile(str(output_path), fps=24, codec="libx264", audio_codec="aac")
    else:
        final_video.write_videofile(str(output_path), fps=24, codec="libx264", audio_codec="aac", verbose=False, logger=None)

    final_video.close()
    if audio:
        audio.close()

    print(f"    âœ“ MoviePy ë Œë”ë§ ì™„ë£Œ: {output_path}")
    return {"video_path": str(output_path), "success": True}


def _save_output_json(script: dict, audio_result: dict, images_result: dict) -> dict:
    """
    íŒŒì´í”„ë¼ì¸ ì¶œë ¥ë¬¼ì„ JSONìœ¼ë¡œ ì €ì¥
    """
    # metadata í´ë” ì‚¬ìš© (ìˆìœ¼ë©´)
    metadata_dir = OUTPUT_DIR / "metadata" if (OUTPUT_DIR / "metadata").exists() else OUTPUT_DIR
    video_dir = OUTPUT_DIR / "video" if (OUTPUT_DIR / "video").exists() else OUTPUT_DIR

    # 1. ìŠ¤í¬ë¦½íŠ¸ ì €ì¥
    script_path = metadata_dir / "script.json"
    with open(script_path, "w", encoding="utf-8") as f:
        json.dump(script, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“„ ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}")

    # 2. ë‚˜ë ˆì´ì…˜ ì €ì¥ (ì”¬ë³„ í…ìŠ¤íŠ¸ + íƒ€ì„ìŠ¤íƒ¬í”„)
    narration_data = {
        "full_text": " ".join([s.get("narration", "") for s in script.get("scenes", [])]),
        "scenes": [],
        "timestamps": audio_result.get("timestamps", []),
        "total_duration": audio_result.get("duration", 0),
        "audio_file": audio_result.get("audio_path", "")
    }

    for scene in script.get("scenes", []):
        narration_data["scenes"].append({
            "id": scene.get("id"),
            "narration": scene.get("narration", ""),
            "duration_seconds": scene.get("duration_seconds", 15)
        })

    narration_path = metadata_dir / "narration.json"
    with open(narration_path, "w", encoding="utf-8") as f:
        json.dump(narration_data, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“„ ë‚˜ë ˆì´ì…˜ ì €ì¥: {narration_path}")

    # 3. ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì €ì¥
    images_data = {
        "count": images_result.get("count", 0),
        "image_paths": images_result.get("image_paths", []),
        "scenes": []
    }

    for i, scene in enumerate(script.get("scenes", [])):
        image_path = images_result.get("image_paths", [])[i] if i < len(images_result.get("image_paths", [])) else ""
        images_data["scenes"].append({
            "id": scene.get("id"),
            "visual_description": scene.get("visual_description", ""),
            "image_path": image_path
        })

    images_path = metadata_dir / "images.json"
    with open(images_path, "w", encoding="utf-8") as f:
        json.dump(images_data, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“„ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì €ì¥: {images_path}")

    # 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¶œë ¥ ìš”ì•½ ì €ì¥
    pipeline_output = {
        "generated_at": datetime.now().isoformat(),
        "project_folder": str(OUTPUT_DIR),
        "title": script.get("title", ""),
        "scene_count": len(script.get("scenes", [])),
        "files": {
            "script": str(script_path),
            "narration": str(narration_path),
            "images": str(images_path),
            "audio": audio_result.get("audio_path", ""),
            "video": str(video_dir / "final_video.mp4")
        },
        "script": script,
        "audio": audio_result,
        "images": images_result
    }

    pipeline_path = metadata_dir / "pipeline_output.json"
    with open(pipeline_path, "w", encoding="utf-8") as f:
        json.dump(pipeline_output, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“„ íŒŒì´í”„ë¼ì¸ ì¶œë ¥ ì €ì¥: {pipeline_path}")

    return {
        "script_path": str(script_path),
        "narration_path": str(narration_path),
        "images_path": str(images_path),
        "pipeline_path": str(pipeline_path)
    }


def _create_placeholder_image(path: Path, scene_id: int, text: str):
    """Placeholder ì´ë¯¸ì§€ ìƒì„±"""
    try:
        from PIL import Image, ImageDraw, ImageFont

        img = Image.new('RGB', (1920, 1080), color=(30, 30, 40))
        draw = ImageDraw.Draw(img)

        for y in range(1080):
            r = int(30 + (y / 1080) * 20)
            g = int(30 + (y / 1080) * 30)
            b = int(40 + (y / 1080) * 40)
            draw.line([(0, y), (1920, y)], fill=(r, g, b))

        try:
            font = ImageFont.truetype("arial.ttf", 48)
            small_font = ImageFont.truetype("arial.ttf", 24)
        except:
            font = ImageFont.load_default()
            small_font = font

        draw.text((960, 480), f"Scene {scene_id}", fill=(255, 255, 255), font=font, anchor="mm")
        wrapped_text = text[:80] + "..." if len(text) > 80 else text
        draw.text((960, 560), wrapped_text, fill=(180, 180, 180), font=small_font, anchor="mm")

        img.save(path)
    except:
        path.touch()


# ============================================================
# ADK TOOLS - FunctionTool ë˜í•‘
# ============================================================

image_generation_tool = FunctionTool(func=generate_images_tool)
audio_generation_tool = FunctionTool(func=generate_audio_tool)
video_render_tool = FunctionTool(func=render_video_tool)


# ============================================================
# AGENTS - LlmAgent ì •ì˜
# ============================================================

# Agent 1: ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± Agent (ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜)
script_writer_agent = LlmAgent(
    name="ScriptWriterAgent",
    model="gemini-2.0-flash",
    instruction="""# í˜ë¥´ì†Œë‚˜: ê¹€ì„œì—° (Seoyeon Kim)

ë‹¹ì‹ ì€ **ê¹€ì„œì—°**, 15ë…„ ê²½ë ¥ì˜ ìœ íŠœë¸Œ êµìœ¡ ì½˜í…ì¸  ì „ë¬¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ê°€ì…ë‹ˆë‹¤.

## í”„ë¡œí•„
- **ê²½ë ¥**: MBC ë‹¤íë©˜í„°ë¦¬ ì‘ê°€ ì¶œì‹ , ìœ íŠœë¸Œ êµìœ¡ ì±„ë„ "ì§€ì‹ì˜ ë°œê²¬" ìˆ˜ì„ ì‘ê°€
- **ëŒ€í‘œì‘**: "AI ì‹œëŒ€ì˜ ìƒì¡´ë²•" (ì¡°íšŒìˆ˜ 500ë§Œ), "ë¯¸ë˜ë¥¼ ì½ëŠ” ë²•" ì‹œë¦¬ì¦ˆ
- **ìˆ˜ìƒ**: 2024 ìœ íŠœë¸Œ í¬ë¦¬ì—ì´í„° ì–´ì›Œë“œ 'ìµœìš°ìˆ˜ êµìœ¡ ì½˜í…ì¸ '
- **ì „ë¬¸ ë¶„ì•¼**: ê¸°ìˆ /ê³¼í•™ íŠ¸ë Œë“œ, ìê¸°ê³„ë°œ, ê²½ì œ/ê¸ˆìœµ

## ì‘ë¬¸ ì² í•™
1. **Hook First**: ì²« 5ì´ˆì— ì‹œì²­ìë¥¼ ì‚¬ë¡œì¡ëŠ” ì§ˆë¬¸ì´ë‚˜ ì¶©ê²©ì  ì‚¬ì‹¤ë¡œ ì‹œì‘
2. **Story Arc**: ë¬¸ì œ ì œê¸° â†’ íƒêµ¬ â†’ í•´ê²°ì±… â†’ í–‰ë™ ì´‰êµ¬ì˜ ì„œì‚¬ êµ¬ì¡°
3. **Conversational Tone**: ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ì–´ì¡°
4. **Visual Sync**: ë‚˜ë ˆì´ì…˜ê³¼ í™”ë©´ì´ ì™„ë²½íˆ ì¼ì¹˜í•˜ë„ë¡ ì‹œê°ì  ë¬˜ì‚¬ í¬í•¨

## ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ê·œì¹™

### êµ¬ì¡°
- **ì¸íŠ¸ë¡œ (15ì´ˆ)**: ê°•ë ¥í•œ í›… + ì£¼ì œ ì†Œê°œ + "ì˜¤ëŠ˜ ì˜ìƒì—ì„œëŠ”..."
- **ë³¸ë¬¸ (ê° 15ì´ˆì”©)**: í•µì‹¬ ê°œë…ë³„ ì„¤ëª…, ì˜ˆì‹œ, ë¹„ìœ  í™œìš©
- **ì•„ì›ƒíŠ¸ë¡œ (15ì´ˆ)**: ìš”ì•½ + CTA ("êµ¬ë…ê³¼ ì¢‹ì•„ìš”...")

### ë‚˜ë ˆì´ì…˜ ìŠ¤íƒ€ì¼
- "~ì…ë‹ˆë‹¤" ëŒ€ì‹  "~ì´ì—ìš”", "~ê±°ë“ ìš”" ë“± ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰¬ìš´ ë¹„ìœ ë¡œ ì„¤ëª…
- ì‹œì²­ìì—ê²Œ ì§ì ‘ ë§í•˜ëŠ” ë“¯í•œ 2ì¸ì¹­ ì‚¬ìš© ("ì—¬ëŸ¬ë¶„ë„ ëŠë¼ì…¨ì£ ?")

### ì¶œë ¥ í˜•ì‹ (JSONë§Œ ì¶œë ¥)
```json
{
    "title": "í´ë¦­ì„ ë¶€ë¥´ëŠ” ë§¤ë ¥ì ì¸ ì œëª©",
    "scenes": [
        {
            "id": 1,
            "narration": "ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‚˜ë ˆì´ì…˜ (2-3ë¬¸ì¥)",
            "visual_description": "Detailed English description for AI image generation, cinematic style, 4K quality",
            "duration_seconds": 15
        }
    ]
}
```

### visual_description ê°€ì´ë“œ
- ì˜ì–´ë¡œ ì‘ì„± (Gemini Imagenìš©)
- êµ¬ì²´ì ì¸ ì¥ë©´ ë¬˜ì‚¬ í¬í•¨
- ìŠ¤íƒ€ì¼ ëª…ì‹œ: cinematic, digital art, photorealistic, minimalist infographic ë“±
- ìƒ‰ê°/ë¶„ìœ„ê¸° í¬í•¨: warm lighting, dark moody atmosphere, bright optimistic tone

## í˜„ì¬ ì‘ì—…
state.topic: ì£¼ì œ
state.duration_minutes: ì˜ìƒ ê¸¸ì´ (ë¶„)

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•œ í›„,
**ë°˜ë“œì‹œ save_script_toolì„ í˜¸ì¶œí•˜ì—¬ ì €ì¥í•˜ì„¸ìš”.**

### ë„êµ¬ í˜¸ì¶œ ë°©ë²•
```python
save_script_tool(script_json={
    "title": "ì œëª©",
    "scenes": [...]
})
```""",
    description="15ë…„ ê²½ë ¥ ìœ íŠœë¸Œ êµìœ¡ ì½˜í…ì¸  ì „ë¬¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ê°€ ê¹€ì„œì—°",
    tools=[FunctionTool(save_script_tool)],
    output_key="script"
)


# Agent 2: ì´ë¯¸ì§€ ìƒì„± Agent (ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜)
image_generator_agent = LlmAgent(
    name="ImageGeneratorAgent",
    model="gemini-2.0-flash",
    instruction="""# í˜ë¥´ì†Œë‚˜: ë°•ì¤€í˜ (Junhyuk Park)

ë‹¹ì‹ ì€ **ë°•ì¤€í˜**, 10ë…„ ê²½ë ¥ì˜ AI ë¹„ì£¼ì–¼ ì•„í‹°ìŠ¤íŠ¸ì´ì í¬ë¦¬ì—ì´í‹°ë¸Œ ë””ë ‰í„°ì…ë‹ˆë‹¤.

## í”„ë¡œí•„
- **ê²½ë ¥**: Pixar ì¸í„´ ì¶œì‹ , ë„·í”Œë¦­ìŠ¤ ì½”ë¦¬ì•„ ì¸ë„¤ì¼ ì•„íŠ¸ ë””ë ‰í„°
- **ëŒ€í‘œì‘**: "ì˜¤ì§•ì–´ ê²Œì„ 2" í‚¤ ë¹„ì£¼ì–¼, "ë” ê¸€ë¡œë¦¬" ì—í”¼ì†Œë“œ ì¸ë„¤ì¼ ì‹œë¦¬ì¦ˆ
- **ìˆ˜ìƒ**: 2025 Adobe Creative Award, Red Dot Design Award
- **ì „ë¬¸ ë¶„ì•¼**: AI ì´ë¯¸ì§€ ìƒì„±, ì‹œë„¤ë§ˆí‹± ë¹„ì£¼ì–¼, ë¸Œëœë“œ ì•„ì´ë´í‹°í‹°

## ë¹„ì£¼ì–¼ ì² í•™
1. **Emotional Impact**: ì´ë¯¸ì§€ í•˜ë‚˜ë¡œ ê°ì •ì„ ì „ë‹¬
2. **Visual Storytelling**: í•œ ì¥ë©´ì´ ì²œ ë§ˆë”” ë§ì„ ëŒ€ì‹ 
3. **Consistency**: ì‹œë¦¬ì¦ˆ ì „ì²´ì˜ ì‹œê°ì  í†µì¼ì„± ìœ ì§€
4. **Trending Aesthetics**: ìµœì‹  ë””ìì¸ íŠ¸ë Œë“œ ë°˜ì˜

## ì´ë¯¸ì§€ ìƒì„± ì›ì¹™

### í”„ë¡¬í”„íŠ¸ ìµœì í™” ì „ëµ
- **êµ¬ë„**: Rule of thirds, leading lines, symmetry í™œìš©
- **ì¡°ëª…**: Golden hour, dramatic lighting, soft diffused light
- **ìŠ¤íƒ€ì¼**: Cinematic 4K, concept art, photorealistic, minimalist
- **ë¶„ìœ„ê¸°**: ì£¼ì œì— ë§ëŠ” color grading (warm/cool/moody)

### êµìœ¡ ì½˜í…ì¸  ë¹„ì£¼ì–¼ ê°€ì´ë“œ
- ì¶”ìƒì  ê°œë… â†’ êµ¬ì²´ì  ë©”íƒ€í¬ë¡œ ì‹œê°í™”
- í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê³µê°„ í™•ë³´ (í•˜ë‹¨ 1/3 ì—¬ë°±)
- ì‹œì²­ì ì‹œì„  ìœ ë„í•˜ëŠ” focal point ì„¤ì •

## í˜„ì¬ ì‘ì—…

state.scriptì˜ scenesì—ì„œ ê° ì”¬ì˜ visual_descriptionì„ ì¶”ì¶œí•˜ì—¬
generate_images_toolì„ í˜¸ì¶œí•˜ì„¸ìš”.

### ë„êµ¬ í˜¸ì¶œ ë°©ë²•
```python
generate_images_tool(visual_descriptions=[
    scene1ì˜ visual_description,
    scene2ì˜ visual_description,
    ...
])
```

ê²°ê³¼ëŠ” ìë™ìœ¼ë¡œ state.imagesì— ì €ì¥ë©ë‹ˆë‹¤.""",
    description="10ë…„ ê²½ë ¥ AI ë¹„ì£¼ì–¼ ì•„í‹°ìŠ¤íŠ¸ ë°•ì¤€í˜, Pixar/ë„·í”Œë¦­ìŠ¤ ì¶œì‹ ",
    tools=[image_generation_tool],
    output_key="images"
)


# Agent 3: ìŒì„± ìƒì„± Agent (ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜)
voice_generator_agent = LlmAgent(
    name="VoiceGeneratorAgent",
    model="gemini-2.0-flash",
    instruction="""# í˜ë¥´ì†Œë‚˜: ì´ìˆ˜ë¯¼ (Sumin Lee)

ë‹¹ì‹ ì€ **ì´ìˆ˜ë¯¼**, 20ë…„ ê²½ë ¥ì˜ ì„±ìš°ì´ì ë³´ì´ìŠ¤ ë””ë ‰í„°ì…ë‹ˆë‹¤.

## í”„ë¡œí•„
- **ê²½ë ¥**: KBS ì „ì† ì„±ìš° ì¶œì‹ , í˜„ì¬ "ë³´ì´ìŠ¤ë© ì½”ë¦¬ì•„" ëŒ€í‘œ
- **ëŒ€í‘œì‘**: ë„·í”Œë¦­ìŠ¤ ë‹¤íë©˜í„°ë¦¬ "í•œêµ­ì¸ì˜ ë°¥ìƒ" ë‚´ë ˆì´ì…˜, ì‚¼ì„± ê°¤ëŸ­ì‹œ ê´‘ê³  VO
- **ìˆ˜ìƒ**: 2023 ëŒ€í•œë¯¼êµ­ ì„±ìš°ëŒ€ìƒ 'ìµœìš°ìˆ˜ ë‚´ë ˆì´ì…˜ìƒ'
- **ì „ë¬¸ ë¶„ì•¼**: ë‹¤íë©˜í„°ë¦¬ ë‚´ë ˆì´ì…˜, ê´‘ê³  VO, ì˜¤ë””ì˜¤ë¶

## ìŒì„± ì² í•™
1. **Authenticity**: ì§„ì •ì„± ìˆëŠ” ëª©ì†Œë¦¬ë¡œ ì‹ ë¢° êµ¬ì¶•
2. **Pacing**: ì •ë³´ ì „ë‹¬ì— ìµœì í™”ëœ ì†ë„ì™€ ì‰¼
3. **Emotional Range**: ì£¼ì œì— ë§ëŠ” í†¤ê³¼ ê°ì • ì¡°ì ˆ
4. **Clarity**: ëª¨ë“  ë‹¨ì–´ê°€ ëª…í™•í•˜ê²Œ ì „ë‹¬ë˜ë„ë¡

## ë‚˜ë ˆì´ì…˜ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ

### êµìœ¡ ì½˜í…ì¸  ìŒì„± íŠ¹ì„±
- **í†¤**: ë”°ëœ»í•˜ê³  ì‹ ë¢°ê° ìˆëŠ” ì¤‘ì €ìŒ
- **ì†ë„**: ë¶„ë‹¹ 150-170ì (ì´í•´í•˜ê¸° ì‰¬ìš´ ì†ë„)
- **ê°•ì¡°**: í•µì‹¬ í‚¤ì›Œë“œì— ìì—°ìŠ¤ëŸ¬ìš´ ê°•ì„¸
- **ì‰¼**: ë¬¸ì¥ ì‚¬ì´ 0.5ì´ˆ, ë‹¨ë½ ì‚¬ì´ 1ì´ˆ

### ê°ì • ë§¤í•‘
- ì¸íŠ¸ë¡œ: í˜¸ê¸°ì‹¬ ìœ ë°œ (ì•½ê°„ ë†’ì€ í†¤)
- ë³¸ë¬¸: ì°¨ë¶„í•œ ì„¤ëª… (ì•ˆì •ì ì¸ í†¤)
- í´ë¼ì´ë§¥ìŠ¤: ê°•ì¡° (ì—ë„ˆì§€ ìƒìŠ¹)
- ì•„ì›ƒíŠ¸ë¡œ: ë”°ëœ»í•œ ë§ˆë¬´ë¦¬ (ë¶€ë“œëŸ¬ìš´ í†¤)

## í˜„ì¬ ì‘ì—…

state.scriptì˜ scenesì—ì„œ ê° ì”¬ì˜ narrationì„ ì¶”ì¶œí•˜ì—¬
generate_audio_toolì„ í˜¸ì¶œí•˜ì„¸ìš”.

### ë„êµ¬ í˜¸ì¶œ ë°©ë²•
```python
generate_audio_tool(narration_texts=[
    scene1ì˜ narration,
    scene2ì˜ narration,
    ...
])
```

ê²°ê³¼(ìŒì„± íŒŒì¼ + íƒ€ì„ìŠ¤íƒ¬í”„)ëŠ” ìë™ìœ¼ë¡œ state.audioì— ì €ì¥ë©ë‹ˆë‹¤.""",
    description="20ë…„ ê²½ë ¥ ì„±ìš° ì´ìˆ˜ë¯¼, KBS ì¶œì‹  ë³´ì´ìŠ¤ ë””ë ‰í„°",
    tools=[audio_generation_tool],
    output_key="audio"
)


# Agent 4: ì˜ìƒ ë Œë”ë§ Agent (ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜)
render_agent = LlmAgent(
    name="RenderAgent",
    model="gemini-2.0-flash",
    instruction="""# í˜ë¥´ì†Œë‚˜: ìµœì˜ì§„ (Youngjin Choi)

ë‹¹ì‹ ì€ **ìµœì˜ì§„**, 12ë…„ ê²½ë ¥ì˜ ì˜ìƒ í¸ì§‘ìì´ì í¬ìŠ¤íŠ¸ í”„ë¡œë•ì…˜ ê°ë…ì…ë‹ˆë‹¤.

## í”„ë¡œí•„
- **ê²½ë ¥**: CJ ENM í¸ì§‘ì‹¤ ì¶œì‹ , í˜„ì¬ "ìŠ¤íŠœë””ì˜¤ ëª¨ì…˜" ëŒ€í‘œ
- **ëŒ€í‘œì‘**: "ë‚˜ í˜¼ì ì‚°ë‹¤" í¸ì§‘, "ìœ í€´ì¦ˆ" ì‹œì¦Œ 1-3, ìœ íŠœë¸Œ "ìŠˆì¹´ì›”ë“œ" í¸ì§‘ ì´ê´„
- **ìˆ˜ìƒ**: 2024 ë°±ìƒì˜ˆìˆ ëŒ€ìƒ 'ê¸°ìˆ ìƒ (í¸ì§‘)', YouTube Creator Award
- **ì „ë¬¸ ë¶„ì•¼**: ì˜ˆëŠ¥/ë‹¤í í¸ì§‘, ëª¨ì…˜ ê·¸ë˜í”½, ì»¬ëŸ¬ ê·¸ë ˆì´ë”©

## í¸ì§‘ ì² í•™
1. **Rhythm**: ìŒì•…ì²˜ëŸ¼ íë¥´ëŠ” ì˜ìƒ ë¦¬ë“¬
2. **Seamless Flow**: ì‹œì²­ìê°€ í¸ì§‘ì„ ëŠë¼ì§€ ëª»í•˜ê²Œ
3. **Visual Hierarchy**: ì¤‘ìš”í•œ ê²ƒì„ ê°•ì¡°í•˜ëŠ” ì‹œê°ì  ìœ„ê³„
4. **Ken Burns Magic**: ì •ì ì¸ ì´ë¯¸ì§€ì— ìƒëª…ì„ ë¶ˆì–´ë„£ëŠ” ëª¨ì…˜

## í¸ì§‘ ê¸°ë²•

### Ken Burns íš¨ê³¼ ì „ëµ
- **Zoom In**: ë””í…Œì¼ ê°•ì¡°, ê¸´ì¥ê° (ê²°ë¡ ë¶€)
- **Zoom Out**: ì „ì²´ ë§¥ë½ ì œì‹œ, ì˜¤í”„ë‹ (ë„ì…ë¶€)
- **Pan Left/Right**: ì‹œê°„ì˜ íë¦„, ë¹„êµ ëŒ€ì¡°
- **Slow Push**: ì ì§„ì  ëª°ì…ê° (ì„¤ëª… ì¥ë©´)

### ì”¬ ì „í™˜ íƒ€ì´ë°
- ë‚˜ë ˆì´ì…˜ ë¬¸ì¥ ëì—ì„œ 0.3ì´ˆ í›„ ì „í™˜
- ìŒì„± íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ì •í™•í•œ ì‹±í¬
- ìì—°ìŠ¤ëŸ¬ìš´ í¬ë¡œìŠ¤í˜ì´ë“œ (0.5ì´ˆ)

### ê¸°ìˆ  ìŠ¤í™
- í•´ìƒë„: 1920x1080 (Full HD)
- í”„ë ˆì„: 24fps (ì‹œë„¤ë§ˆí‹± ëŠë‚Œ)
- ì½”ë±: H.264 (í˜¸í™˜ì„± ìµœì )
- ì˜¤ë””ì˜¤: AAC 192kbps

## í˜„ì¬ ì‘ì—…

state.imagesì™€ state.audioë¥¼ ì‚¬ìš©í•˜ì—¬ render_video_toolì„ í˜¸ì¶œí•˜ì„¸ìš”.

### ë„êµ¬ í˜¸ì¶œ ë°©ë²•
```python
render_video_tool(
    image_paths=state.images["image_paths"],
    audio_path=state.audio["audio_path"],
    timestamps=state.audio["timestamps"]
)
```

ê²°ê³¼(ìµœì¢… MP4 ì˜ìƒ)ëŠ” ìë™ìœ¼ë¡œ state.videoì— ì €ì¥ë©ë‹ˆë‹¤.""",
    description="12ë…„ ê²½ë ¥ ì˜ìƒ í¸ì§‘ì ìµœì˜ì§„, CJ ENM ì¶œì‹  í¬ìŠ¤íŠ¸í”„ë¡œë•ì…˜ ê°ë…",
    tools=[video_render_tool],
    output_key="video"
)


# ============================================================
# ORCHESTRATOR - SequentialAgent
# ============================================================

# ì´ë¯¸ì§€ + ìŒì„± ë³‘ë ¬ ìƒì„±
media_parallel_agent = ParallelAgent(
    name="MediaParallelAgent",
    sub_agents=[image_generator_agent, voice_generator_agent],
    description="ì´ë¯¸ì§€ì™€ ìŒì„±ì„ ë³‘ë ¬ë¡œ ìƒì„±"
)

# ì „ì²´ íŒŒì´í”„ë¼ì¸
video_pipeline_agent = SequentialAgent(
    name="VideoPipelineAgent",
    sub_agents=[
        script_writer_agent,    # 1. ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
        media_parallel_agent,   # 2. ì´ë¯¸ì§€ + ìŒì„± (ë³‘ë ¬)
        render_agent            # 3. ë Œë”ë§
    ],
    description="ìœ íŠœë¸Œ ì˜ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸"
)


# ============================================================
# RUNNER - íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
# ============================================================

async def run_pipeline(topic: str, duration_minutes: int = 1) -> Optional[str]:
    """ADK íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    global OUTPUT_DIR, GLOBAL_STATE

    # GLOBAL_STATE ì´ˆê¸°í™”
    GLOBAL_STATE = {
        "script": None,
        "images": None,
        "audio": None,
        "video": None,
    }

    print("=" * 60)
    print("ğŸ¬ KRACKER MVP - Google ADK Multi-Agent Pipeline")
    print("=" * 60)
    print(f"ğŸ“Œ ì£¼ì œ: {topic}")
    print(f"â±ï¸  ê¸¸ì´: {duration_minutes}ë¶„")
    print("=" * 60)

    # í”„ë¡œì íŠ¸ í´ë” ìƒì„± (ì£¼ì œ ê¸°ë°˜)
    OUTPUT_DIR = create_project_folder(topic)

    # ì„¸ì…˜ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    session_service = InMemorySessionService()

    # ëŸ¬ë„ˆ ìƒì„±
    runner = Runner(
        agent=video_pipeline_agent,
        app_name="kracker_mvp",
        session_service=session_service
    )

    # ì„¸ì…˜ ìƒì„±
    session = await session_service.create_session(
        app_name="kracker_mvp",
        user_id="user_1"
    )

    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    session.state["topic"] = topic
    session.state["duration_minutes"] = duration_minutes

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    print("\nğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    print("-" * 40)

    user_message = types.Content(
        role="user",
        parts=[types.Part(text=f"ì£¼ì œ: {topic}, ê¸¸ì´: {duration_minutes}ë¶„ ì˜ìƒì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")]
    )

    try:
        async for event in runner.run_async(
            session_id=session.id,
            user_id="user_1",
            new_message=user_message
        ):
            # ì´ë²¤íŠ¸ ì²˜ë¦¬
            if hasattr(event, 'agent_name'):
                print(f"\nğŸ“ Agent: {event.agent_name}")

            if hasattr(event, 'content') and event.content:
                # ê²°ê³¼ ì¶œë ¥
                for part in event.content.parts:
                    if hasattr(part, 'text') and part.text:
                        text = part.text[:200]
                        print(f"   {text}...")

    except Exception as e:
        error_str = str(e)
        if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
            print("\nâš ï¸  API í• ë‹¹ëŸ‰ ì´ˆê³¼ (429 RESOURCE_EXHAUSTED)")
            print("    â†’ 1-2ë¶„ ê¸°ë‹¤ë¦° í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            print("    â†’ ë˜ëŠ” ë‹¤ë¥¸ API í‚¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        elif "404" in error_str or "NOT_FOUND" in error_str:
            print(f"\nâš ï¸  ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (404 NOT_FOUND)")
            print(f"    â†’ ëª¨ë¸ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”: {error_str[:100]}")
        else:
            print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì—ëŸ¬: {e}")
            import traceback
            traceback.print_exc()
        return None

    # ê²°ê³¼ í™•ì¸
    print("\n" + "-" * 40)

    # ë””ë²„ê·¸: í˜„ì¬ state ì¶œë ¥ (GLOBAL_STATE ì‚¬ìš©)
    print("\nğŸ“Š State ë””ë²„ê·¸ (GLOBAL_STATE):")
    print(f"  - script: {'ìˆìŒ' if GLOBAL_STATE.get('script') else 'ì—†ìŒ'}")
    print(f"  - images: {'ìˆìŒ' if GLOBAL_STATE.get('images') else 'ì—†ìŒ'}")
    print(f"  - audio: {'ìˆìŒ' if GLOBAL_STATE.get('audio') else 'ì—†ìŒ'}")
    print(f"  - video: {'ìˆìŒ' if GLOBAL_STATE.get('video') else 'ì—†ìŒ'}")

    # JSON ì¶œë ¥ ì €ì¥ (GLOBAL_STATE ì‚¬ìš©)
    script_data = GLOBAL_STATE.get("script") or {}
    images_data = GLOBAL_STATE.get("images") or {}
    audio_data = GLOBAL_STATE.get("audio") or {}

    if script_data and (images_data or audio_data):
        print("\nğŸ“„ JSON ì¶œë ¥ ì €ì¥ ì¤‘...")
        # ìŠ¤í¬ë¦½íŠ¸ê°€ ë¬¸ìì—´ì´ë©´ JSONìœ¼ë¡œ íŒŒì‹±
        if isinstance(script_data, str):
            try:
                script_data = json.loads(script_data)
            except:
                script_data = {"title": "Unknown", "scenes": []}
        _save_output_json(script_data, audio_data or {}, images_data or {})

    video_result = GLOBAL_STATE.get("video") or {}
    video_path = video_result.get("video_path", "") if isinstance(video_result, dict) else ""

    # state.videoê°€ ì—†ì–´ë„ í”„ë¡œì íŠ¸ í´ë”ì—ì„œ ì˜ìƒ í™•ì¸
    video_dir = OUTPUT_DIR / "video" if (OUTPUT_DIR / "video").exists() else OUTPUT_DIR
    fallback_video_path = video_dir / "final_video.mp4"

    if video_path and Path(video_path).exists():
        print("\n" + "=" * 60)
        print("âœ… ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“ í”„ë¡œì íŠ¸ í´ë”: {OUTPUT_DIR}")
        print(f"ğŸ“ í´ë” êµ¬ì¡°:")
        print(f"   â”œâ”€â”€ images/      - ì”¬ë³„ ì´ë¯¸ì§€")
        print(f"   â”œâ”€â”€ audio/       - ë‚˜ë ˆì´ì…˜ ìŒì„±")
        print(f"   â”œâ”€â”€ video/       - ìµœì¢… ì˜ìƒ")
        print(f"   â””â”€â”€ metadata/    - JSON ë©”íƒ€ë°ì´í„°")
        print(f"ğŸ¥ ì˜ìƒ íŒŒì¼: {video_path}")
        print("=" * 60)
        return video_path
    elif fallback_video_path.exists():
        print("\n" + "=" * 60)
        print("âœ… ì™„ë£Œ! (fallback)")
        print("=" * 60)
        print(f"ğŸ“ í”„ë¡œì íŠ¸ í´ë”: {OUTPUT_DIR}")
        print(f"ğŸ“ í´ë” êµ¬ì¡°:")
        print(f"   â”œâ”€â”€ images/      - ì”¬ë³„ ì´ë¯¸ì§€")
        print(f"   â”œâ”€â”€ audio/       - ë‚˜ë ˆì´ì…˜ ìŒì„±")
        print(f"   â”œâ”€â”€ video/       - ìµœì¢… ì˜ìƒ")
        print(f"   â””â”€â”€ metadata/    - JSON ë©”íƒ€ë°ì´í„°")
        print(f"ğŸ¥ ì˜ìƒ íŒŒì¼: {fallback_video_path}")
        print("=" * 60)
        return str(fallback_video_path)
    else:
        print("\nâŒ ì˜ìƒ ìƒì„± ì‹¤íŒ¨")
        print("ğŸ’¡ ìˆ˜ë™ ë Œë”ë§ ì‹œë„...")

        # ìˆ˜ë™ìœ¼ë¡œ ë Œë”ë§ ì‹œë„ (GLOBAL_STATE ì‚¬ìš©, tool_context ì—†ì´ ì§ì ‘ í˜¸ì¶œ)
        images = GLOBAL_STATE.get("images") or {}
        audio = GLOBAL_STATE.get("audio") or {}

        if images and audio:
            try:
                image_paths = images.get("image_paths", [])
                audio_path_val = audio.get("audio_path", "")
                timestamps = audio.get("timestamps", [])

                if image_paths and audio_path_val:
                    # _fallback_moviepy_render ì§ì ‘ í˜¸ì¶œ (tool_context ë¶ˆí•„ìš”)
                    result = _fallback_moviepy_render(image_paths, audio_path_val, timestamps)
                    if result.get("success"):
                        GLOBAL_STATE["video"] = result  # ìˆ˜ë™ìœ¼ë¡œ state ì—…ë°ì´íŠ¸
                        print(f"âœ… ìˆ˜ë™ ë Œë”ë§ ì„±ê³µ: {result['video_path']}")
                        return result["video_path"]
            except Exception as render_err:
                print(f"âŒ ìˆ˜ë™ ë Œë”ë§ ì‹¤íŒ¨: {render_err}")

        return None


# ============================================================
# FALLBACK - ADK ì—†ì„ ë•Œ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸
# ============================================================

def run_simple_pipeline(topic: str, duration_minutes: int = 1) -> Optional[str]:
    """ADK ì—†ì„ ë•Œ ë‹¨ìˆœ íŒŒì´í”„ë¼ì¸"""
    global OUTPUT_DIR

    print("=" * 60)
    print("ğŸ¬ KRACKER MVP - Simple Pipeline (No ADK)")
    print("=" * 60)
    print(f"ğŸ“Œ ì£¼ì œ: {topic}")
    print(f"â±ï¸  ê¸¸ì´: {duration_minutes}ë¶„")
    print("=" * 60)

    # Step 1: ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    print("\nğŸ“ Step 1: ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
    num_scenes = max(2, duration_minutes * 60 // 15)

    response = gemini_client.models.generate_content(
        model="gemini-2.0-flash",
        contents=f"""ë‹¹ì‹ ì€ ìœ íŠœë¸Œ êµìœ¡ ì½˜í…ì¸  ìŠ¤í¬ë¦½íŠ¸ ì‘ê°€ì…ë‹ˆë‹¤.

ì£¼ì œ: {topic}
ì˜ìƒ ê¸¸ì´: {duration_minutes}ë¶„
ì”¬ ê°œìˆ˜: {num_scenes}ê°œ

JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
{{
    "title": "ì˜ìƒ ì œëª©",
    "scenes": [
        {{
            "id": 1,
            "narration": "ë‚˜ë ˆì´ì…˜ (í•œêµ­ì–´)",
            "visual_description": "Image description (English)",
            "duration_seconds": 15
        }}
    ]
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
    )

    text = response.text.strip()
    if "```json" in text:
        text = text.split("```json")[1].split("```")[0]
    elif "```" in text:
        text = text.split("```")[1].split("```")[0]

    try:
        script = json.loads(text.strip())
    except:
        script = {
            "title": topic,
            "scenes": [{"id": 1, "narration": topic, "visual_description": "AI concept art", "duration_seconds": 60}]
        }

    print(f"  âœ“ ì œëª©: {script['title']}")
    print(f"  âœ“ ì”¬ ê°œìˆ˜: {len(script['scenes'])}")

    # í”„ë¡œì íŠ¸ í´ë” ìƒì„±
    OUTPUT_DIR = create_project_folder(script['title'])

    # ìŠ¤í¬ë¦½íŠ¸ ì €ì¥ (metadata í´ë”ì—)
    metadata_dir = OUTPUT_DIR / "metadata"
    with open(metadata_dir / "script.json", "w", encoding="utf-8") as f:
        json.dump(script, f, ensure_ascii=False, indent=2)

    # Step 2: ì´ë¯¸ì§€ ìƒì„±
    print("\nğŸ¨ Step 2: ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
    visual_descriptions = [s["visual_description"] for s in script["scenes"]]
    images_result = generate_images_tool(visual_descriptions)
    print(f"  âœ“ ì´ë¯¸ì§€: {images_result['count']}ì¥")

    # Step 3: ìŒì„± ìƒì„±
    print("\nğŸ™ï¸ Step 3: ìŒì„± ìƒì„± ì¤‘...")
    narrations = [s["narration"] for s in script["scenes"]]
    audio_result = generate_audio_tool(narrations)
    print(f"  âœ“ ìŒì„±: {audio_result['audio_path']}")

    # Step 3.5: JSON ì¶œë ¥ ì €ì¥
    print("\nğŸ“„ Step 3.5: JSON ì¶œë ¥ ì €ì¥ ì¤‘...")
    _save_output_json(script, audio_result, images_result)

    # Step 4: ì˜ìƒ ë Œë”ë§
    print("\nğŸ¬ Step 4: ì˜ìƒ ë Œë”ë§ ì¤‘...")
    video_result = render_video_tool(
        images_result["image_paths"],
        audio_result["audio_path"],
        audio_result["timestamps"]
    )

    if video_result["success"]:
        print("\n" + "=" * 60)
        print("âœ… ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“ í”„ë¡œì íŠ¸ í´ë”: {OUTPUT_DIR}")
        print(f"ğŸ“ í´ë” êµ¬ì¡°:")
        print(f"   â”œâ”€â”€ images/      - ì”¬ë³„ ì´ë¯¸ì§€")
        print(f"   â”œâ”€â”€ audio/       - ë‚˜ë ˆì´ì…˜ ìŒì„±")
        print(f"   â”œâ”€â”€ video/       - ìµœì¢… ì˜ìƒ")
        print(f"   â””â”€â”€ metadata/    - JSON ë©”íƒ€ë°ì´í„°")
        print(f"ğŸ¥ ì˜ìƒ íŒŒì¼: {video_result['video_path']}")
        print("=" * 60)
        return video_result["video_path"]
    else:
        print("\nâŒ ì‹¤íŒ¨")
        return None


# ============================================================
# MAIN
# ============================================================

def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python mvp_video_pipeline.py \"ì£¼ì œ\" [ë¶„]")
        print("ì˜ˆì‹œ: python mvp_video_pipeline.py \"AIê°€ ë°”ê¾¸ëŠ” ë¯¸ë˜ ì§ì—…\" 1")
        return

    topic = sys.argv[1]
    duration = float(sys.argv[2]) if len(sys.argv) > 2 else 1

    # ADK ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    try:
        from google.adk.agents import LlmAgent
        print("âœ“ Google ADK ê°ì§€ë¨")
        asyncio.run(run_pipeline(topic, duration))
    except ImportError:
        print("âš  Google ADK ë¯¸ì„¤ì¹˜. ë‹¨ìˆœ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©")
        run_simple_pipeline(topic, duration)


if __name__ == "__main__":
    main()
